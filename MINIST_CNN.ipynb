{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_idx3(dataset_file):\n",
    "    # read binary data\n",
    "    bin_data = open(dataset_file, 'rb').read()\n",
    "\n",
    "    # read headers, the order is: magic number, number of images, height, width\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii'\n",
    "    magic_num, img_num, rows, cols = \\\n",
    "        struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print 'magic_num: %d, img_num: %d, image size: %d*%d' % \\\n",
    "          (magic_num, img_num, rows, cols)\n",
    "\n",
    "    #decode data\n",
    "    img_size = rows * cols\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>' + str(img_size) + 'B'\n",
    "    images = np.empty((img_num, rows, cols))\n",
    "    for i in range(img_num):\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset))\\\n",
    "            .reshape((rows, cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print 'Decoded %d' % (i + 1)\n",
    "    return images\n",
    "\n",
    "\n",
    "def decode_idx1(label_file):\n",
    "    # read binary data\n",
    "    bin_data = open(label_file, 'rb').read()\n",
    "\n",
    "    # read headers, the order is: magic number, number of images, height, width\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_num, img_num = \\\n",
    "        struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print 'magic_num: %d, img_num: %d' % (magic_num, img_num)\n",
    "\n",
    "    #decode data\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = np.empty(img_num)\n",
    "    for i in range(img_num):\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print 'Decoded %d' % (i + 1)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic_num: 2051, img_num: 60000, image size: 28*28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 40000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 60000\nmagic_num: 2049, img_num: 60000\nDecoded 10000\nDecoded 20000\nDecoded 30000\nDecoded 40000\nDecoded 50000\nDecoded 60000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic_num: 2051, img_num: 10000, image size: 28*28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 10000\nmagic_num: 2049, img_num: 10000\nDecoded 10000\n"
     ]
    }
   ],
   "source": [
    "train_data_file = 'train-images.idx3-ubyte'\n",
    "train_labels_file = 'train-labels.idx1-ubyte'\n",
    "test_data_file = 't10k-images.idx3-ubyte'\n",
    "test_labels_file = 't10k-labels.idx1-ubyte'\n",
    "\n",
    "train_dataset = decode_idx3(train_data_file)\n",
    "train_labels = decode_idx1(train_labels_file)\n",
    "test_dataset = decode_idx3(test_data_file)\n",
    "test_labels = decode_idx1(test_labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "# Preprocessing\n",
    "# randomize both dataset and labels\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Turn pixel to binary\n",
    "train_dataset = (train_dataset[:,:,:] > 127) * 255.0\n",
    "test_dataset = (test_dataset[:,:,:] > 127) * 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "num_labels = 10\n",
    "\n",
    "# reshape labels to [0.0, 1.0, ..., 0.0]\n",
    "train_labels = np.arange(num_labels) == train_labels[:, None]\n",
    "test_labels = np.arange(num_labels) == test_labels[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Zero mean and Normalize\n",
    "img_range = 255.0;\n",
    "train_dataset = 1.0 * (train_dataset - img_range / 2) / img_range\n",
    "test_dataset = 1.0 * (test_dataset - img_range / 2) / img_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# split test dataset to valid and test two parts\n",
    "valid_dataset = test_dataset[:5000]\n",
    "valid_labels = test_labels[:5000]\n",
    "test_dataset = test_dataset[5000:10000]\n",
    "test_labels = test_labels[5000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_dataset.reshape(\n",
    "    train_dataset.shape[0], image_size, image_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48s - loss: 2.2984 - acc: 0.1473\nEpoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 2.2656 - acc: 0.2210\nEpoch 3/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49s - loss: 1.9204 - acc: 0.3150\nEpoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 1.3836 - acc: 0.5267\nEpoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.9575 - acc: 0.6772\nEpoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48s - loss: 0.7770 - acc: 0.7396\nEpoch 7/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.6767 - acc: 0.7729\nEpoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.6063 - acc: 0.7961\nEpoch 9/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.5562 - acc: 0.8130\nEpoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.5176 - acc: 0.8262\nEpoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.4856 - acc: 0.8381\nEpoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.4497 - acc: 0.8515\nEpoch 13/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.4308 - acc: 0.8578\nEpoch 14/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.4119 - acc: 0.8647\nEpoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51s - loss: 0.3934 - acc: 0.8735\nEpoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48s - loss: 0.3734 - acc: 0.8785\nEpoch 17/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.3577 - acc: 0.8864\nEpoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.3438 - acc: 0.8861\nEpoch 19/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.3359 - acc: 0.8911\nEpoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.3231 - acc: 0.8962\nEpoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.3137 - acc: 0.9002\nEpoch 22/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.2989 - acc: 0.9052\nEpoch 23/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.2960 - acc: 0.9068\nEpoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.2836 - acc: 0.9110\nEpoch 25/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47s - loss: 0.2760 - acc: 0.9114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4eb73dc090>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialization\n",
    "image_size = 28\n",
    "truncatedN = keras.initializers.\\\n",
    "    TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0, nesterov=True)\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(image_size, image_size, 1),\n",
    "                             activation = 'relu', kernel_initializer=truncatedN))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Convolution2D(32, (3, 3),\n",
    "                             activation = 'relu', kernel_initializer=truncatedN))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=128, activation='relu', \n",
    "                     kernel_initializer=truncatedN))\n",
    "classifier.add(Dense(units=10, activation='softmax', \n",
    "                     kernel_initializer=truncatedN))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = sgd, loss = 'categorical_crossentropy',\n",
    "                   metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(train_dataset)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "classifier.fit_generator(datagen.flow(\n",
    "    train_dataset, train_labels, batch_size=64), \n",
    "    steps_per_epoch=len(train_dataset) / 64, epochs=25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = valid_dataset.reshape(\n",
    "    valid_dataset.shape[0], image_size, image_size, 1)\n",
    "test_dataset = test_dataset.reshape(\n",
    "    test_dataset.shape[0], image_size, image_size, 1)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_valid = classifier.predict(valid_dataset)\n",
    "y_pred_test = classifier.predict(test_dataset)\n",
    "\n",
    "sum = np.sum(np.argmax(y_pred_valid[i]) == np.argmax(valid_labels[i]) \n",
    "             for i in range(0, valid_labels.shape[0]))\n",
    "acc_valid = sum*1.0/5000\n",
    "sum = np.sum(np.argmax(y_pred_test[i]) == np.argmax(test_labels[i]) \n",
    "             for i in range(0, test_labels.shape[0]))\n",
    "acc_test = sum*1.0/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_dataset[1000].reshape(1, image_size, image_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.05748035e-05,   8.61559357e-08,   8.05468517e-06,\n          3.93664304e-05,   3.86036164e-03,   4.31162971e-06,\n          3.25071755e-06,   2.23221767e-04,   1.58394547e-03,\n          9.94246900e-01]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU4Zfaur3bo0FGD+odsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4eb4048450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_data.reshape(image_size, image_size), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU4Zfaur3+9UFGveqp6cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4eb3db4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import misc\n",
    "num = misc.imread('download.png')\n",
    "num = num[:,:,0].reshape(image_size, image_size)\n",
    "plt.imshow(num, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.02290763e-08,   6.46872156e-09,   5.26038320e-07,\n          6.02907221e-06,   5.96929422e-05,   2.30388787e-06,\n          8.84559004e-09,   9.98119242e-04,   2.98237521e-03,\n          9.95950937e-01]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = num.reshape(1, image_size, image_size, 1)\n",
    "num = 1.0 * (num - 127.5) / 255.0\n",
    "classifier.predict(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bbde0e2e099b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save a keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Save a keras model\n",
    "from keras.models import load_model\n",
    "classifier.save_weights('model.hdf5')\n",
    "with open('model.json', 'w') as f:\n",
    "    f.write(classifier.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}